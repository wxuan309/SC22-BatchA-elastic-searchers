{"backend_state":"running","connection_file":"/projects/013ca607-9af4-4b8b-9eb4-c9fa83e65e2d/.local/share/jupyter/runtime/kernel-37c80f32-110b-4e69-9b40-925b42c7bc43.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"colab":{"name":"linear_regression_numpy_tutorial.ipynb","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1655226610999,"exec_count":2,"id":"267233","input":"import numpy as np\nimport matplotlib.pyplot as plt","kernel":"python3-ubuntu","metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1627498066861,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"IecuRdF1a-sG"},"pos":1,"start":1655226610989,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226611682,"exec_count":3,"id":"b156b7","input":"my_list = [0,1,2,3]\nlen(my_list)","kernel":"python3-ubuntu","output":{"0":{"data":{"text/plain":"4"},"exec_count":3}},"pos":3,"start":1655226611670,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226612011,"exec_count":4,"id":"0d9fcc","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42) # Why 42 (It works well for computer science) - https://medium.com/@leticia.b/the-story-of-seed-42-874953452b94\n\n# randomly generate x which is a vector of 100 points \nx = np.random.rand(1000, 1)\n\n# define exact linear function y = 1 + 2x + epsilon where epsilon (0.1*random numbers)\ny = 1 + 2 * x + .1 * np.random.randn(1000, 1)\nlen(y)","kernel":"python3-ubuntu","metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1627498568931,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"BYHvay0xa-sK"},"output":{"0":{"data":{"text/plain":"1000"},"exec_count":4}},"pos":4,"start":1655226611972,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226612522,"exec_count":5,"id":"cc0bff","input":"# Shuffles the indices\nidx = np.arange(1000)\n\nnp.random.shuffle(idx)\n\n# Uses first 80 random indices for train\ntrain_idx = idx[:800]\n\n# Uses the remaining indices for validation\nval_idx = idx[800:]\n\n# Generates train and validation sets\nx_train, y_train = x[train_idx], y[train_idx]\nx_val, y_val = x[val_idx], y[val_idx]\n","kernel":"python3-ubuntu","metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1627498579768,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"_ntl2sX3a-sL"},"pos":6,"start":1655226612509,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226613735,"exec_count":6,"id":"192955","input":"plt.figure(figsize=(10,5))\n\n# plot the train set \nplt.subplot(1,2,1)\nplt.scatter(x_train,y_train, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Train')\nplt.grid('on')\n\n# plot the validation set \nplt.subplot(1,2,2)\nplt.scatter(x_val,x_val)  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\n\nplt.show()","kernel":"python3-ubuntu","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1627498583872,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"W1JhyZ_Na-sM","outputId":"909f5fd9-c203-45cf-d41f-58b09bb727ef"},"output":{"0":{"data":{"image/png":"38c0e08df4354c34831fa8189a767878d970101f","text/plain":"<Figure size 720x360 with 2 Axes>"},"metadata":{"image/png":{"height":342,"width":620},"needs_background":"light"}}},"pos":8,"start":1655226613020,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226615539,"exec_count":7,"id":"66bd53","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42)\n\n# Initializes parameters \"a\" and \"b\" randomly - they don't need to be good yet\na = np.random.randn(1)\nb = np.random.randn(1)\n\n# print values of a and b \nprint(a, b)\n","kernel":"python3-ubuntu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1627498594869,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"MjeQPrOKa-sP","outputId":"fe881c09-932e-46f0-9f40-79b6b5c69617"},"output":{"0":{"name":"stdout","text":"[0.49671415] [-0.1382643]\n"}},"pos":10,"start":1655226615528,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226615929,"exec_count":8,"id":"8f16e1","input":"# Initialization of hyper-parameters (in our case, only learning rate and number of epochs)\n\n# Sets learning rate (how much the AI conforms to each set of feedbacks)\nlr = 1e-1\n# Defines number of epochs (how many times training is repeated)\nn_epochs = 1000","kernel":"python3-ubuntu","metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1627498605594,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"xaIPfjB1a-sP"},"pos":11,"start":1655226615922,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226617058,"exec_count":9,"id":"d8737b","input":"for epoch in range(n_epochs):\n    # Computes our model's predicted output\n    yhat = a + b * x_train\n    \n    # How wrong is our model? That's the error! \n    error = (y_train - yhat)\n    \n    # It is a regression, so it computes mean squared error (MSE)\n    loss = (error ** 2).mean()\n    \n    # Computes gradients for both \"a\" and \"b\" parameters\n    a_grad = -2 * error.mean()\n    b_grad = -2 * (x_train * error).mean()\n    \n    # Updates parameters using gradients and the learning rate\n    a = a - lr * a_grad\n    b = b - lr * b_grad\n    \nprint(a, b)","kernel":"python3-ubuntu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1627499222901,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"IEGhbnhoa-sQ","outputId":"6df14990-801c-4030-bd27-e2c19b95c577"},"output":{"0":{"name":"stdout","text":"[1.01733799] [1.98435464]\n"}},"pos":13,"start":1655226616993,"state":"done","type":"cell"}
{"cell_type":"code","end":1655226644428,"exec_count":14,"id":"e027ae","input":"plt.figure(figsize=(10,5))\ny_vals = a + b * x_val\nplt.plot(x_val, y_vals, '--')\n\nplt.scatter(x_val,y_val, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\nplt.show()","kernel":"python3-ubuntu","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1627499225902,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"V9wnGeT_eou8","outputId":"1dc573e8-ebd4-4861-94e0-ff1a6d4229d3"},"output":{"0":{"data":{"image/png":"5cf1ccc18c34f512eb93edbf42cf9154d7978671","text/plain":"<Figure size 720x360 with 1 Axes>"},"metadata":{"image/png":{"height":342,"width":619},"needs_background":"light"}}},"pos":14,"start":1655226644024,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"11da77","input":"","metadata":{"id":"owTTVO4Ba-sY"},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2c6076","input":"","metadata":{"id":"8vkl-uJMa-sZ"},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"46e7d5","input":"","metadata":{"id":"l5xP_R3ya-sZ"},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"5f4f4f","input":"","metadata":{"id":"VPv4Rha8a-sa"},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7ac00d","input":"","metadata":{"id":"mdxlUKLka-sZ"},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8e55d2","input":"","metadata":{"id":"bUuZFIRxa-sZ"},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d7a141","input":"","metadata":{"id":"cvxyHdHha-sa"},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"eff878","input":"","metadata":{"id":"ox6WlPb7a-sa"},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f4713f","input":"","metadata":{"id":"7ubqNNVxa-sZ"},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"76185a","input":"from sklearn.linear_model import LinearRegression\nlinr = LinearRegression()\nlinr.fit(x_train, y_train)\nprint(linr.intercept_, linr.coef_[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":885,"status":"ok","timestamp":1627498630865,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"jkPf0bt4a-sV","outputId":"422ab4c2-fceb-490e-ca2d-b45f09b26cff"},"output":{"0":{"name":"stdout","output_type":"stream","text":"[1.02354075] [1.96896447]\n"}},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"0b7ba7","input":"## The results!\n\nThey match up to 6 decimal places — we have a fully working implementation of linear regression using Numpy.","metadata":{"id":"yE4V3P9aa-sX"},"pos":17,"type":"cell"}
{"cell_type":"markdown","id":"223bff","input":"## linear regression using numpy ","metadata":{"id":"gi4pQP8Ia-sO"},"pos":9,"type":"cell"}
{"cell_type":"markdown","id":"6bffd4","input":"### For each epoch, there are 5 training steps:\n* Compute model’s predictions \n* Compute the error (the difference between the actual value and predicted value) \n* Compute the loss ( mean square error = the average of (error)^2)\n* Compute the gradients for every parameter (require calculus)\n* Update the parameters a and b","metadata":{"id":"Tmk5nl_Va-sQ"},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"74ddf3","input":"## check our results use Scikit-learn's linear regression\n\nJust to make sure we haven’t done any mistakes in our code, we can use Scikit-Learn’s Linear Regression to fit the model and compare the coefficients.\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html","metadata":{"id":"cbeaQMpna-sR"},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"980dba","input":"## split data into train and validation sets (80/20)","metadata":{"id":"irEOBQoca-sL"},"pos":5,"type":"cell"}
{"cell_type":"markdown","id":"bde102","input":"# Linear regression using NumPy\n\n","metadata":{"id":"K_X2fB9ta-rv"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"f44367","input":"## plot the train and validation sets","metadata":{"id":"DCCwyhkya-sM"},"pos":7,"type":"cell"}
{"cell_type":"markdown","id":"fd3879","input":"## Data Generation","metadata":{"id":"JlrQHpg8a-sI"},"pos":2,"type":"cell"}
{"end":1655226661856,"exec_count":15,"id":"56476e","input":"plt.figure(figsize=(10,5))\ny_pred = a + b * x_train\nplt.plot(x_train, y_pred, '--')\n\nplt.scatter(x_train,y_train, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Train')\nplt.grid('on')\nplt.show()","kernel":"python3-ubuntu","output":{"0":{"data":{"image/png":"18628dc2a6ebf52796e283a5e3c85ef6517dffdd","text/plain":"<Figure size 720x360 with 1 Axes>"},"metadata":{"image/png":{"height":342,"width":619},"needs_background":"light"}}},"pos":13.5,"start":1655226661471,"state":"done","type":"cell"}
{"id":0,"time":1655226679030,"type":"user"}
{"last_load":1655226527196,"type":"file"}